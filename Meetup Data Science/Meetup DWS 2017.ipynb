{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc, lit, udf, struct, collect_list, explode, size, concat_ws, split\n",
    "from pyspark.sql.types import ArrayType, DoubleType, IntegerType, StringType, StructType, StructField\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class timeit():\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        \n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print('{ runtime: %6.2f sec }' % (time.time() - self.start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nvd3_stat import Nvd3\n",
    "nv = Nvd3()\n",
    "nv.reloadNVD3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Artist Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip the following steps if the data has already been saved ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def intOrNeg(value):\n",
    "#     try:\n",
    "#         i = int(value)\n",
    "#     except:\n",
    "#         i = -9999999\n",
    "#     return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rawArtistData = sc.textFile(\"/data/lastfm/artist_data.txt\")\n",
    "# rawArtistData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rawArtistData.filter(lambda row: \"\\t\" not in row).count() # to be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# artistData = (rawArtistData.filter(lambda row: \"\\t\" in row)\n",
    "#                            .map(lambda row: row.split(\"\\t\"))\n",
    "#                            .map(lambda row: Row(artistid=intOrNeg(row[0]), artistname=row[1]))\n",
    "# ).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# artistData.where(artistData.artistid == -9999999).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# artistData = artistData.where(artistData.artistid != -9999999).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# artistData.write.parquet(\"/data/lastfm/artist_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start here if the data has already been saved and load itÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artistData = spark.read.parquet(\"/data/lastfm/artist_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artistData.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawArtistAlias = sc.textFile(\"/data/lastfm/artist_alias.txt\")\n",
    "artistAlias = (rawArtistAlias.map(lambda row: row.split(\"\\t\"))\n",
    "                             .filter(lambda row: row[0] != \"\")\n",
    "                             .map(lambda row: (int(row[0]), int(row[1])))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idmap = dict(artistAlias.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artistData.where(artistData.artistid.isin([2097164, 1001134])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcidmap = sc.broadcast(idmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Artist Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip the following steps if the data has already been saved ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rawUserArtistData = sc.textFile(\"/data/lastfm/user_artist_data.txt\", 6)\n",
    "\n",
    "# userArtistData1 = (rawUserArtistData\n",
    "#                    .map(lambda row: row.split(\" \"))\n",
    "#                    .map(lambda row: Row(userid      = int(row[0]),\n",
    "#                                         rawartistid = int(row[1]), \n",
    "#                                         artistid    = bcidmap.value.get(int(row[1]), int(row[1])),\n",
    "#                                         playcount   = int(row[2])))\n",
    "# ).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# userArtistData2 = (userArtistData1.select([\"userid\",\"artistid\",\"playcount\"])\n",
    "#                                   .groupBy([\"userid\",\"artistid\"])\n",
    "#                                   .sum(\"playcount\")\n",
    "#                                   .withColumnRenamed(\"sum(playcount)\", \"playcount\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many artists do users listen to\n",
    "\n",
    "# userGroups = (userArtistData2.select([\"artistid\", \"userId\"])\n",
    "#                              .groupBy(col(\"userid\"))\n",
    "#                              .count()\n",
    "#              ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hist = userGroups.rdd.values().histogram([0, 5, 10, 20,40,80,160,320,640,1280,2560,5120,10240,20480,450000])\n",
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# db = nv.discreteBarChart()\n",
    "\n",
    "# db.plot({\"Bucket\":hist[0][1:], \"Count\":hist[1]}, \"Bucket\", \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove upper \"outliers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# userArtistData = (userGroups.where(col(\"count\") >= 10).where(col(\"count\") <= 1500)\n",
    "#                             .select([\"userid\"])\n",
    "#                             .join(userArtistData2, on=\"userid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (userArtistData.groupby(\"artistid\")\n",
    "#                .count()\n",
    "#                .join(artistData, on=\"artistid\")\n",
    "#                .sort(desc(\"count\"))\n",
    "# ).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove artist 1034635 ( [unknown] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# userArtistData = userArtistData.where(userArtistData.artistid != 1034635)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !hdfs dfs -rm -r /data/lastfm/user_artist_data.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# userArtistData.write.parquet(\"/data/lastfm/user_artist_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start here if the data has already been saved and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userArtistData = spark.read.parquet(\"/data/lastfm/user_artist_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userArtistData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userGroups = (userArtistData.select([\"artistid\", \"userId\"])\n",
    "                            .groupBy(col(\"userid\"))\n",
    "                            .count())\n",
    "\n",
    "hist = userGroups.rdd.values().histogram([20,40,80,160,240,320,480,560,640,800, 960,1280, 1500])\n",
    "db = nv.discreteBarChart()\n",
    "\n",
    "db.plot({\"Bucket\":hist[0][1:], \"Count\":hist[1]}, \"Bucket\", \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "def alsModel(df, rank, maxIter, regParam, alpha):\n",
    "    als = ALS(rank=rank, maxIter=maxIter, regParam=regParam, alpha=alpha, \n",
    "              implicitPrefs=True,\n",
    "              userCol=\"userid\", itemCol=\"artistid\", ratingCol=\"playcount\")\n",
    "    return als.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note: Fast but can lead to NAN in predictions when algorithm runs out of training or test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, test = userArtistData.randomSplit([0.9, 0.1])\n",
    "training.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = alsModel(training, rank=10, maxIter=5, regParam=0.01, alpha=1.0)\n",
    "model = alsModel(training, rank=10, maxIter=5, regParam=1.0, alpha=40.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually examinig some example users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compareFavs(user, count=20):\n",
    "    test_user = test.where(col(\"userid\") == user).cache()\n",
    "    training_user = training.where(col(\"userid\") == user)\n",
    "\n",
    "    # 1) Extract Favourites from training set\n",
    "    training_favs = (training_user.join(artistData, on=\"artistid\")\n",
    "                                  .sort(desc(\"playcount\"))\n",
    "                                  .select(col(\"playcount\").alias(\"training_playcount\"), \n",
    "                                          col(\"artistname\").alias(\"training_artist\"))\n",
    "                    ).limit(count).toPandas()\n",
    "\n",
    "    # 2) Extract Favourites from test set (cond = True)\n",
    "    test_favs = (test_user.join(artistData, on=\"artistid\")\n",
    "                          .sort(desc(\"playcount\"))\n",
    "                          .select(col(\"playcount\").alias(\"test_playcount\"), \n",
    "                                  col(\"artistname\").alias(\"test_artist\"))\n",
    "                 \n",
    "                ).limit(count).toPandas()\n",
    "\n",
    "    # 3) Extract Favourites from test set (cond = True)\n",
    "    predictions = (model.transform(test_user.select([\"userid\", \"artistid\"]))\n",
    "                        .dropna()).limit(count)\n",
    "\n",
    "    recommendations = (predictions.join(artistData, on=\"artistid\")\n",
    "                                  .sort(desc(\"prediction\"))\n",
    "                                  .select(col(\"prediction\"), \n",
    "                                          col(\"artistname\").alias(\"recommended_artist\")) \n",
    "                      ).toPandas()\n",
    "\n",
    "    test_user.unpersist()\n",
    "    return training_favs.join(recommendations.join(test_favs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = 2268277\n",
    "compareFavs(user).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = 2294531\n",
    "compareFavs(user).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By calulating the AUC for one example user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "allArtists = np.array(userArtistData.select(\"artistid\")\n",
    "                                    .distinct()\n",
    "                                    .rdd\n",
    "                                    .flatMap(lambda x: x)\n",
    "                                    .collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample a random set from all unique artists of same length as input, however without elements of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(positive, all):\n",
    "    negative = np.random.choice(all, size=2*positive.size)\n",
    "    return np.setdiff1d(negative, positive)[:positive.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user = 2294531\n",
    "user = 2268277"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take the listened artist in the test set as \"condition true\" (what the user really listened) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testPositive = (test.where(col(\"userid\") == user)\n",
    "                    .select([\"userid\", \"artistid\"]))\n",
    "                    \n",
    "testPositive.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... and randomly select a list of artists from all artist this user never listened to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testPositiveList = np.array(testPositive.rdd.flatMap(lambda x: x).collect())\n",
    "testNegativeList = sample(testPositiveList, allArtists)\n",
    "\n",
    "testNegative = (spark.createDataFrame(pd.DataFrame({\"artistid\":testNegativeList,\n",
    "                                                    \"userid\":[user]*len(testNegativeList)})))\n",
    "\n",
    "testNegative.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the predictions for the positive and negative test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positivePredictions = model.transform(testPositive).dropna().withColumn(\"cond\", lit(1))\n",
    "\n",
    "negativePredictions = model.transform(testNegative).dropna().withColumn(\"cond\", lit(0))\n",
    "\n",
    "predictions = positivePredictions.union(negativePredictions).select([\"cond\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Spark BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "toDouble = udf(lambda x: float(x), DoubleType())\n",
    "\n",
    "def spark_metric(predictions, roc=True):\n",
    "    metricName=\"areaUnderROC\" if roc else \"areaUnderPR\"\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"cond\", metricName=metricName)\n",
    "    metric = evaluator.evaluate(predictions.select([\"cond\", toDouble(\"prediction\").alias(\"prediction\")]))\n",
    "    return metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with timeit():\n",
    "    auc1 = spark_metric(predictions)\n",
    "    aucpr1 = spark_metric(predictions, roc=False)\n",
    "\n",
    "print(auc1, aucpr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Spark + Scikit Learn Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skm_metrics(predictions, roc=True):\n",
    "    preds = predictions.toPandas()\n",
    "    if roc:\n",
    "        auc = skm.roc_auc_score(preds[\"cond\"], preds[\"prediction\"])\n",
    "    else:\n",
    "        auc = skm.average_precision_score(preds[\"cond\"], preds[\"prediction\"])\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with timeit():\n",
    "    auc2   = skm_metrics(predictions)\n",
    "    aucpr2 = skm_metrics(predictions, False)\n",
    "\n",
    "print(auc2, aucpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rocChart(positivePredictions, negativePredictions):\n",
    "    preds = positivePredictions.select(\"prediction\", \"cond\").union(\n",
    "            negativePredictions.select(\"prediction\", \"cond\")).toPandas()\n",
    "    fpr, tpr, _ = skm.roc_curve(preds[\"cond\"], preds[\"prediction\"])\n",
    "\n",
    "    roc = nv.lineChart()\n",
    "    \n",
    "    config = {\"width\":600, \"height\":500, \"color\":nv.c20(3,5,7,8,1),\n",
    "              \"xDomain\":[0,1], \"yDomain\":[0,1.05],\n",
    "              \"xAxis\":{\"axisLabel\":\"False Positive Rate\", \"tickFormat\":\",.2f\"},\n",
    "              \"yAxis\":{\"axisLabel\":\"True Positive Rate\", \"tickFormat\":\",.2f\"}\n",
    "             }\n",
    "    \n",
    "    roc.addLine({\"FPR\":fpr, \"TPR\":tpr}, \"FPR\", \"TPR\")\n",
    "    roc.addLine({\"X\":[0,1], \"Baseline\":[0,1]}, \"X\", \"Baseline\", lineAttributes={\"style\":\"dotted\"})\n",
    "    \n",
    "    roc.plot(config=config)\n",
    "\n",
    "rocChart(positivePredictions, negativePredictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By a \"mean AUC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make a broadcast variable out of allArtists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import collect_list, explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcAllArtists = sc.broadcast(allArtists)\n",
    "\n",
    "def sample2(positive):\n",
    "    all = bcAllArtists.value\n",
    "    plen = len(positive)\n",
    "    negative = np.random.choice(all, size=2*plen)\n",
    "    return np.setdiff1d(negative, positive)[:plen].tolist()\n",
    "\n",
    "sampleUdf = udf(sample2, ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positiveTest = test.select([\"userid\", \"artistid\"]).withColumn(\"cond\", lit(1))\n",
    "positiveTest.cache()\n",
    "\n",
    "negativeTest = (test.groupBy(\"userid\")\n",
    "                    .agg(collect_list(\"artistid\").alias(\"positiveAtists\"))\n",
    "                    .withColumn(\"negativeArtists\", sampleUdf('positiveAtists'))\n",
    "                    .select([\"userid\", explode(\"negativeArtists\").alias(\"artistid\")])\n",
    ")\n",
    "negativeTest.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positivePredictions = (model.transform(positiveTest).dropna().withColumn(\"cond\", lit(1))).cache()\n",
    "negativePredictions = (model.transform(negativeTest).dropna().withColumn(\"cond\", lit(0))).cache()\n",
    "\n",
    "predictions = positivePredictions.select([\"userid\", \"cond\", \"prediction\"]).union(\n",
    "                negativePredictions.select([\"userid\", \"cond\", \"prediction\"])\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def metrics(conds, predictions, roc=True):\n",
    "    if len(conds) < 2 or len(predictions) < 2:\n",
    "        return None\n",
    "    if len(set(conds)) == 1:\n",
    "        return None\n",
    "\n",
    "    if roc:\n",
    "        auc = skm.roc_auc_score(conds, predictions)\n",
    "    else:\n",
    "        auc = skm.average_precision_score(conds, predictions)\n",
    "\n",
    "    return auc.item()       # convert numpy type to python type\n",
    "\n",
    "\n",
    "def auc(conds, predictions):\n",
    "    return metrics(conds, predictions, True)\n",
    "    \n",
    "def aucpr(conds, predictions):\n",
    "    return metrics(conds, predictions, False)\n",
    "\n",
    "   \n",
    "aucUdf = udf(auc, DoubleType())\n",
    "aucprUdf = udf(aucpr, DoubleType())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mean AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allAucs = (predictions.groupby(\"userid\")\n",
    "                      .agg(collect_list(\"cond\").alias(\"conds\"), \n",
    "                           collect_list(\"prediction\").alias(\"predictions\"))\n",
    "                      .withColumn(\"auc\", aucUdf(\"conds\", \"predictions\"))\n",
    ")\n",
    "\n",
    "allAucs.describe(\"auc\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allAucprs = (predictions.groupby(\"userid\")\n",
    "                        .agg(collect_list(\"cond\").alias(\"conds\"), \n",
    "                             collect_list(\"prediction\").alias(\"predictions\"))\n",
    "                        .withColumn(\"aucpr\", aucprUdf(\"conds\", \"predictions\"))\n",
    ")\n",
    "\n",
    "allAucprs.describe(\"aucpr\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.0 (HDP)",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
